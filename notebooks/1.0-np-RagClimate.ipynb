{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import HuggingFaceDatasetLoader # permet de télécharger un dataset HuggingFace\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings # on récupère un embedding adapté aux données HuggingFace\n",
    "from langchain.indexes.vectorstore import VectorstoreIndexCreator # permet à Langchain de transformer les données en vecteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"tweet_eval\"\n",
    "page_content_column = \"text\"\n",
    "name = \"stance_climate\"\n",
    "\n",
    "loader = HuggingFaceDatasetLoader(dataset_name, page_content_column, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nath\\AppData\\Local\\Temp\\ipykernel_26032\\3645008222.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings()\n",
      "C:\\Users\\Nath\\AppData\\Local\\Temp\\ipykernel_26032\\3645008222.py:1: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings = HuggingFaceEmbeddings()\n",
      "c:\\Users\\Nath\\Desktop\\RAG_CLIMATE_1.0\\rag_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Nath\\Desktop\\RAG_CLIMATE_1.0\\rag_env\\Lib\\site-packages\\langchain\\indexes\\vectorstore.py:171: UserWarning: Using InMemoryVectorStore as the default vectorstore.This memory store won't persist data. You should explicitlyspecify a vectorstore when using VectorstoreIndexCreator\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "index = VectorstoreIndexCreator(embedding=embeddings).from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain.indexes.vectorstore.VectorStoreIndexWrapper'>\n"
     ]
    }
   ],
   "source": [
    "print(type(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv \n",
    "import os\n",
    "\n",
    "load_dotenv() # output = True : le code permet de récupérer les informations directement dans le fichier .env, True signifiant que le code fonctionne correctement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = [\"HUGGINGFACEHUB_API_TOKEN\"] # os.environ permet de récupérer les variables du fichier .env, ici on récupère la clé api(de cette manière la clé api est sécurisée dans un fichier .env à part)\n",
    "# print(api_key) ne pas afficher la clé api car le git push ne fonctionnerait pas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nath\\Desktop\\RAG_CLIMATE_1.0\\rag_env\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nath\\Desktop\\RAG_CLIMATE_1.0\\rag_env\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "hf = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"openai-community/gpt2\", # on spécifie le modèle ici\n",
    "    task=\"text-generation\",\n",
    "    device=-1, # valeur 0 fait les calculs GPU, valeur -1 fait les calculs CPU\n",
    "    pipeline_kwargs={\"max_new_tokens\": 50}, # génère un certain nbre de nouveaux mots, nouveaux tokens (c'est la taille de la prédiction réalisée)\n",
    "    model_kwargs={\"temperature\": 0} # permet de régler à quel point la sortie du modèle est aléatoire\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query):\n",
    "    result = index.query(query, llm=hf)\n",
    "    target_string = \"Helpful Answer:\"\n",
    "    return result[result.find(target_string)+len(target_string):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Use the following pieces of context to answer the question at the end. If you don\\'t know the answer, just say that you don\\'t know, don\\'t try to make up an answer.\\n\\n\"What do you do to help reverse climate change? Tweet your tips to inspire others! #Tip #SavePolarBear #SemST\"\\n\\n\"#Follow @user US leader in weather #riskmanagement . Helping the world\\'s #economy adapt to climate change. #SemST\"\\n\\n\"We\\'re growing vegetables at home. Tell your friends and followers what you\\'re doing for climate! #myChangeForClimate #SemST\"\\n\\n\"#CSOTA is trending at #3 in Canada on Twitter Now w/ 3,800 Tweets from the #Climate Summit of the Americas! #sm #socialmedia #SemST\"\\n\\nQuestion: Generate a tweet about climate change\\nHelpful Answer:\\n\\nThis question answers a question about how to create a #ClimateTweet. To find those words you add a note to your Twitter profile. Please note that this is a different Tweet format than Tweet in which you use the word climate here. This'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Generate a tweet about climate change\"\n",
    "\n",
    "generate_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Climate Change is a global event. In the context of science, it might sound reasonable to conclude that the world will warm during the next half-decade. Yet that \"global warming\" theory is not credible at all. Climate change is the result'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is climate change\"\n",
    "\n",
    "generate_answer(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
